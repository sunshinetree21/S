{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차검증(Cross-Validation Test)\n",
    "\n",
    "</br>\n",
    "\n",
    "## 💡 교차검증이란?\n",
    "\n",
    "- 교차검증(Cross-validation)은 머신러닝에서 모델의 일반화 능력을 평가하고 검증하기 위한 기술이다.\n",
    "- 이 방법은 학습 데이터를 여러 부분집합(subsets)으로 나누고, 이 중 일부를 학습에, 나머지를 검증에 사용하는 반복적인 과정을 포함한다.\n",
    "\n",
    "- 가장 흔히 사용되는 교차 검증 방법 중 하나는 k-겹 교차 검증(k-fold cross-validation)으로,</br>\n",
    "\t여기서 데이터는 'k'개의 부분집합으로 나누어지며, 각 부분집합은 순차적으로 검증 집합으로 사용된다.\n",
    "\n",
    "- $\\cal D_{train}$을 K 등분해서 각각을 K번 검증한 후 그 평균을 취한다.\n",
    "\n",
    "\t<img src=\"https://github.com/ElaYJ/Study_Machine_Learning/assets/153154981/8f131703-aedc-4c7a-b25e-1dd1d7fb1a51\" width=\"57%\" height=\"57%\">\n",
    "\n",
    "</br>\n",
    "\n",
    "- 교차 검증의 목적은 모델이 새로운 데이터에 대해 어떻게 성능을 낼지를 평가하는 것이다.\n",
    "- 이 방법은 모델이 특정 학습 데이터셋에 과적합되는 것을 방지하고, 모델의 성능을 더 신뢰성 있게 추정할 수 있게 해준다.\n",
    "\n",
    "- 각 반복에서 모델은 서로 다른 학습 및 검증 데이터셋으로 테스트되므로,</br>\n",
    "\t교차 검증을 통해 얻은 성능 평가는 모델이 다양한 데이터에 얼마나 잘 일반화되는지를 더 잘 반영한다.\n",
    "\n",
    "- 그러나 교차 검증은 추가적인 계산 비용을 필요로 하며, 특히 k가 크거나 데이터셋이 매우 큰 경우에는 시간이 오래 걸릴 수 있다.\n",
    "- 또한, 데이터의 분포가 불균형하거나 특정 패턴을 따르는 경우, 교차 검증의 결과가 왜곡될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔰 교차검증 구현\n",
    "\n",
    "- K-Fold Cross Validation --> sklearn.model_selection.`KFold`\n",
    "\n",
    "\n",
    "#### --▶ Simple Example 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터: [2 3 4 5 6 7 8 9], 검증 데이터: [0 1]\n",
      "훈련 데이터: [0 1 4 5 6 7 8 9], 검증 데이터: [2 3]\n",
      "훈련 데이터: [0 1 2 3 6 7 8 9], 검증 데이터: [4 5]\n",
      "훈련 데이터: [0 1 2 3 4 5 8 9], 검증 데이터: [6 7]\n",
      "훈련 데이터: [0 1 2 3 4 5 6 7], 검증 데이터: [8 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=False) # 1\n",
    "\n",
    "for train_idx, valid_idx in folds.split(data):\n",
    "    print(f'훈련 데이터: {data[train_idx]}, 검증 데이터: {data[valid_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --▶ Simple Example 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "KFold(n_splits=2, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "\n",
    "kf = KFold(n_splits=2)\n",
    "\n",
    "print(kf.get_n_splits(X))\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- idx\n",
      "[2 3] [0 1]\n",
      "--- train data\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "--- validation data\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "--- idx\n",
      "[0 1] [2 3]\n",
      "--- train data\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "--- validation data\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in kf.split(X):\n",
    "    print('--- idx')\n",
    "    print(train_idx, test_idx)\n",
    "    print('--- train data')\n",
    "    print(X[train_idx])\n",
    "    print('--- validation data')\n",
    "    print(X[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔰 와인 맛 분류 데이터 ➡ KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "red_wine = pd.read_csv(\"../dataset/winequality-red.csv\", sep=';')\n",
    "white_wine = pd.read_csv(\"../dataset/winequality-white.csv\", sep=';')\n",
    "\n",
    "red_wine['color'] = 1.\n",
    "white_wine['color'] = 0.\n",
    "\n",
    "wine = pd.concat([red_wine, white_wine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['taste'] = [1. if grade > 5 else 0. for grade in wine['quality']]\n",
    "\n",
    "X = wine.drop(['taste','quality'], axis=1) #--> column drop\n",
    "y = wine['taste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7294593034442948\n",
      "Test Acc: 0.7161538461538461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "wine_tree = DecisionTreeClassifier(max_depth=2, random_state=13)\n",
    "wine_tree.fit(X_train, y_train) #<--(features, labels)\n",
    "\n",
    "y_pred_tr = wine_tree.predict(X_train)\n",
    "y_pred_test = wine_tree.predict(X_test)\n",
    "\n",
    "print('Train Acc:', accuracy_score(y_train, y_pred_tr)) #--> 훈련용 데이터의 정확도\n",
    "print('Test Acc:', accuracy_score(y_test, y_pred_test)) #--> 테스트용 데이터의 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --▶ K-Fold: 5-fold 구현\n",
    "\n",
    "- `KFold`는 데이터를 나눈 Index를 반환한다.\n",
    "\n",
    "- 각각의 fold에 대한 학습 후 정확도(Accuracy) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "wine_tree_cv = DecisionTreeClassifier(max_depth=2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x000002126D47D200>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold.split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5197 1300 <class 'numpy.ndarray'>\n",
      "5197 1300 <class 'numpy.ndarray'>\n",
      "5198 1299 <class 'numpy.ndarray'>\n",
      "5198 1299 <class 'numpy.ndarray'>\n",
      "5198 1299 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in kfold.split(X):\n",
    "    print(len(train_idx), len(test_idx), type(train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "[1. 1. 1. ... 0. 1. 1.]\n",
      "[0. 0. 1. ... 0. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[0. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6007692307692307,\n",
       " 0.6884615384615385,\n",
       " 0.7090069284064665,\n",
       " 0.7628945342571208,\n",
       " 0.7867590454195535]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_accuracy = []\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    wine_tree_cv.fit(X_train, y_train)\n",
    "    pred = wine_tree_cv.predict(X_test)\n",
    "    print(pred)\n",
    "    cv_accuracy.append(accuracy_score(y_test, pred))\n",
    "\n",
    "cv_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --▶ 5-fold의 Acc 평균\n",
    "\n",
    "- 각 Accuracy의 분산이 크지 않다면 평균을 대표값으로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.709578255462782"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔰 와인 맛 분류 데이터 ➡ Stratified KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --▶ Stratified K-Fold: 5-fold 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 1. 1.]\n",
      "[1. 0. 1. ... 1. 1. 1.]\n",
      "[0. 0. 1. ... 1. 1. 1.]\n",
      "[0. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 0. ... 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5523076923076923,\n",
       " 0.6884615384615385,\n",
       " 0.7143956889915319,\n",
       " 0.7321016166281755,\n",
       " 0.7567359507313318]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5)\n",
    "wine_tree_cv = DecisionTreeClassifier(max_depth=2, random_state=13)\n",
    "\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_idx, test_idx in skfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    wine_tree_cv.fit(X_train, y_train)\n",
    "    pred = wine_tree_cv.predict(X_test)\n",
    "    print(pred)\n",
    "    cv_accuracy.append(accuracy_score(y_test, pred))\n",
    "\n",
    "cv_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --▶ Stratified 5-fold의 Acc 평균\n",
    "\n",
    "- Accuracy의 평균이 KFold보다 더 나쁘다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6888004974240539"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "## 🔰 `cross_val_score`\n",
    "\n",
    "- 교차검증을 보다 가편하게 실행해주는 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55230769, 0.68846154, 0.71439569, 0.73210162, 0.75673595])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5)\n",
    "wine_tree_cv = DecisionTreeClassifier(max_depth=2, random_state=13)\n",
    "\n",
    "cross_val_score(wine_tree_cv, X, y, scoring=None, cv=skfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50076923, 0.62615385, 0.69745958, 0.7582756 , 0.74903772])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5)\n",
    "wine_tree_cv = DecisionTreeClassifier(max_depth=5, random_state=13)\n",
    "\n",
    "cross_val_score(wine_tree_cv, X, y, scoring=None, cv=skfold)\n",
    "#--> depth가 높다고 무조건 acc가 좋아지는 것도 아니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skfold_depth(depth):\n",
    "\timport numpy as np\n",
    "\tfrom sklearn.model_selection import cross_val_score\n",
    "\n",
    "\tskfold = StratifiedKFold(n_splits=5)\n",
    "\twine_tree_cv = DecisionTreeClassifier(max_depth=depth, random_state=13)\n",
    "\n",
    "\tcv_score = cross_val_score(wine_tree_cv, X, y, scoring=None, cv=skfold)\n",
    "\tcv_avg = np.mean(cv_score)\n",
    "\n",
    "\tprint(cv_score, \"--> average:\", cv_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55230769 0.68846154 0.71439569 0.73210162 0.75673595] --> average: 0.6888004974240539\n"
     ]
    }
   ],
   "source": [
    "skfold_depth(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56846154 0.68846154 0.71439569 0.73210162 0.75673595] --> average: 0.6920312666548233\n"
     ]
    }
   ],
   "source": [
    "skfold_depth(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50076923 0.62615385 0.69745958 0.7582756  0.74903772] --> average: 0.6663391958311127\n"
     ]
    }
   ],
   "source": [
    "skfold_depth(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 depth가 높다고 accuracy가 마냥 좋아지는 것도 아니다.!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "## 🔰 `cross_validate`\n",
    "\n",
    "- train score와 함께 보고 싶을 때 사용할 수 있는 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0279274 , 0.03194451, 0.03193855, 0.02194929, 0.02889085]),\n",
       " 'score_time': array([0.006984  , 0.00496078, 0.00199699, 0.00299072, 0.00299215]),\n",
       " 'test_score': array([0.50076923, 0.62615385, 0.69745958, 0.7582756 , 0.74903772]),\n",
       " 'train_score': array([0.78795459, 0.78045026, 0.77568295, 0.76356291, 0.76279338])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cross_validate(wine_tree_cv, X, y, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 과적합 현상이 나타나 있다.\n",
    "\n",
    "- 교차검증한 train_score가 test_score보다 더 높게 나타나고 있으므로 과적합 모델임을 알 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
